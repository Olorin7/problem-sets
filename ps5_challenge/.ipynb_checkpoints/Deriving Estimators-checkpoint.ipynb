{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "In this problem, you will be deriving the *maximum likelihood estimate* (MLE) for the binomial distribution, the *maximum a posteriori* (MAP) estimate for the beta-binomial model, and the *posterior mean* (PM) estimate for the beta-binomial model. \n",
    "\n",
    "**You must show all your work, and format your derivations using LaTeX. Equations that do not use LaTeX will not receive full credit.** \n",
    "\n",
    "To align your equations, you may find the `align*` LaTeX environment useful. Take a look at the source of the following cell for an example of how to use it (note that the `&` symbol is how it determines where to line up the equations, and the `\\\\` is a line break):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "f(x) &= \\int x^2\\ \\mathrm{d}x\\\\\n",
    "&= \\frac{1}{3} x^3\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part A (0.3 points)\n",
    "\n",
    "First, we will derive the MLE for the binomial distribution. The equation for the binomial likelihood is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta; n, k) = \\frac{n!}{k!(n-k)!} \\theta^k (1 - \\theta)^{(n-k)}\n",
    "$$\n",
    "\n",
    "where $\\theta$ is the probability of observing $X=1$, $n$ is the number of times we have observed a value of $X$, and $k$ is the number of times we have observed $X=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">In order to derive the maximum likelihood estimate for the binomial likelihood, we will need to take the derivative of the *log*-likelihood function, $\\log\\mathcal{L}(\\theta; n, k)$. Write down the equation for this log-likelihood.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d8751726274a8973170d3261613b19b7",
     "grade": true,
     "grade_id": "log-likelihood",
     "points": 0.1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Now, find the value of $\\theta$ which maximizes this log-likelihood. Call this variable $\\theta_{MLE}$. To do this, you will need to compute the derivative of $\\log\\mathcal{L}(\\theta; n, k)$ with respect to $\\theta$. Make sure you write down all your steps! The last step of your derivation should be an equation for $\\theta_{MLE}$ in terms of $k$ and $n$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eff42abaaf4654a2a1dddf5fef69edc3",
     "grade": true,
     "grade_id": "d-log-likelihood",
     "points": 0.2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part B (0.4 points)\n",
    "\n",
    "Now, we will derive the MAP estimate of the beta-binomial model. The equation for the beta distribution is:\n",
    "\n",
    "$$\n",
    "p(\\theta; \\alpha, \\beta) = \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)}\n",
    "$$\n",
    "\n",
    "where $B(\\alpha, \\beta)$ is the [Beta function](http://en.wikipedia.org/wiki/Beta_function). Combined with the binomial likelihood, the posterior distribution is given by:\n",
    "\n",
    "$$\n",
    "p(\\theta\\ |\\ n, k; \\alpha, \\beta)= \\frac{1}{Z}p(n, k\\ |\\ \\theta)p(\\theta; \\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "where $Z$ is a normalizing constant.\n",
    "\n",
    "To find the MAP estimate of $\\theta$ (which we will call $\\theta_{MAP}$), we need to find the maximum of this posterior distribution. To do this, we can again compute the log-posterior, and then take the derivative with respect to $\\theta$, similar to how we computed the MLE estimate of the binomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Find the value for $\\theta_{MAP}$ in terms of $\\alpha$, $\\beta$, $n$, and $k$. Make sure you show all your steps!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Note: the $\\alpha$ and $\\beta$ parameters used here are NOT the same as $V_H$ and $V_T$ in the lecture slides. So, your final answer will not look identical to the MAP equation given in lecture. If you look at how $V_H$ and $V_T$ are defined with respect to $\\alpha$ and $\\beta$ in the slides, though, you should find that your answer here is actually the same as the one in lecture if you substitute the variables in correctly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3b919c6382bedcae6c14d34c7e05ca0f",
     "grade": true,
     "grade_id": "map",
     "points": 0.2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "As we have seen, MLE and MAP are two different ways to estimate the parameter $\\theta$ based on data that we have seen. Explain what the difference between these two methods is. What does $\\theta_{MAP}$ take into account that $\\theta_{MLE}$ does not?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d563802b04d1e53bc6b5694daa7c3ead",
     "grade": true,
     "grade_id": "mle-map-difference",
     "points": 0.2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part C (0.3 points)\n",
    "\n",
    "Now, we will derive the posterior mean of the beta-binomial model. The beta-binomial model has a nice property called *conjugacy*, which means that the posterior distribution has the same form as the prior distribution. In this case, our prior is a beta distribution, so the posterior is also beta. So, our first task is to determine the actual form (i.e., the parameters) of this new beta distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Use Bayes' rule to compute the posterior over $\\theta$, which you should call $p(\\theta\\ |\\ n, k; \\alpha, \\beta)$. Any constant term (i.e. that doesn't include $\\theta$) you can lump together into a single normalizing constant $\\frac{1}{Z}$. Your final answer should be in terms of $Z$, $\\theta$, $\\alpha$, $\\beta$, $n$, and $k$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "24228d216a434b5a653116e96d1bf03d",
     "grade": true,
     "grade_id": "posterior",
     "points": 0.1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Compare your equation for the posterior distribution with the general form of the beta distribution above. What are the parameters of this new beta distribution, which we'll denote $\\alpha^\\prime$ and $\\beta^\\prime$? What is $Z$? Write the equations for $\\alpha^\\prime$, $\\beta^\\prime$, and $Z$ in the cell below (they should be in terms of $\\alpha$, $\\beta$, $n$, and/or $k$):\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "608abb84b80bb3e8d2fa703e78bb2175",
     "grade": true,
     "grade_id": "posterior-params",
     "points": 0.1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Now that we have the parameters of the posterior distribution, we can compute the posterior mean, $\\theta_{PM}$. Look up the mean of the beta distribution [on Wikipedia](http://en.wikipedia.org/wiki/Beta_distribution), and report two equations: first, what $\\theta_{PM}$ is in terms of $\\alpha^\\prime$ and $\\beta^\\prime$; and second, what $\\theta_{PM}$ is in terms of $\\alpha$, $\\beta$, $k$, and $n$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "Note: as above, the $\\alpha$ and $\\beta$ parameters used here are NOT the same as $V_H$ and $V_T$ in the lecture slides. So, your final answer will not look identical to the PM equation given in lecture. If you look at how $V_H$ and $V_T$ are defined with respect to $\\alpha$ and $\\beta$ in the slides, though, you should find that your answer here is actually the same as the one in lecture if you substitute the variables in correctly.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "26b0ff7b114766e5f25c8652a0df5163",
     "grade": true,
     "grade_id": "posterior-mean",
     "points": 0.1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your problem set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
