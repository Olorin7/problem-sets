{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bias_and_variance import print_equation, format_equation\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-info\">**Hint**: Much of the material covered in this problem is introduced in the Geman et al. (1992) reading. If you are having trouble with the conceptual questions, this might be a good place to look.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "We wish to evaluate the performance of a learning algorithm that takes a set of $(x,y)$ pairs as input and selects a function $g(x)$, which predicts the value of $y$ for a given $x$ (that is, for a given $(x,y)$ pair, $g(x)$ should approximate $y$).\n",
    "\n",
    "We will evaluate the 'fit' of the functions that our learning algorithm selects using the *mean squared error* (MSE) between $g(x)$ and $y$. For a set of $n$ data points $\\{ (x_1, y_1), \\ldots, (x_n,y_n) \\}$, the MSE associated with a function $g$ is calculated as\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^n \\left ( y_i - g(x_i) \\right )^2 .\n",
    "$$\n",
    "\n",
    "The set of candidate functions that we will allow our algorithm to consider is the set of $k$th-order polynomials. This means that our hypothesis space will contain all functions of the form $g(x) = p_kx^k + p_{k-1} x^{k-1} + \\ldots + p_{1} x + p_0$. These functions are entirely characterized by their coefficient vector ${\\bf p} = (p_k, p_{k-1}, \\ldots, p_0)$, and become much more flexible as $k$ increases (think about the difference between linear ($k=1$), quadratic ($k=2$), and cubic ($k=3$) functions). If we are given a set of $(x,y)$ pairs, it is straightforward to find the $k$th-order polynomial that minimizes the MSE between $g(x)$ and the observed $y$ values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-info\">For those who have done some statistics, the calculation for finding ${\\bf p}$ is just a case of linear regression where the various powers of $x$ are the predictors</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "In this problem, we'll be trying to learn the function $g(x)$ that generated some data with the addition of some Gaussian (i.e., normally distributed) noise. The data is a $110\\times 2$ array, where the first column corresponds to the $x$ coordinate, and the second column corresponds to the $y$ coordinate (which is the function evaluated at the corresponding $x$ value, i.e. $y = g(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "data = np.load(\"data/xy_data.npy\")\n",
    "\n",
    "# only show the first ten points, since there are a lot\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "You will use this data to train and evaluate your learning algorithm.\n",
    "  \n",
    "A \"learning algorithm\" which finds a polynomial of given degree that minimizes the MSE on a set of $(x,y)$ coordinates is implemented in Python with the `np.polyfit` command. You can use `p = np.polyfit(x, y, k)` to return the coefficient vector ${\\bf p}$ for the $k$th-order polynomial $g$ that best fits (i.e., has the smallest $MSE$ on) the $x$ and $y$ coordinates in `x` and `y`.\n",
    "\n",
    "For example, to fit a 4th-order polynomial to the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# fit the 4th order polynomial\n",
    "p = np.polyfit(data[:, 0], data[:, 1], 4)\n",
    "print(\"Vector of coefficients: \" + str(p))\n",
    "\n",
    "# display the resulting equation\n",
    "print_equation(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "You can calculate the values of $g$ at a set of $x$ coordinates using the command `np.polyval`. For example, if you wanted to compute $g(x)$ at $x=0$, $x=0.5$, and $x=1$, you could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "np.polyval(p, np.array([0, 0.5, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part A (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Run the following cell to call `make_polynomial_fit_and_graph`, which creates an IPython *widget* that will allow you to explore what happens when you try to fit polynomials of different orders to different subsets of the data. You should read the source code to see how this is accomplished.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "819d0263f55eb9fc3bec63416edf4881",
     "grade": false,
     "grade_id": "make_polynomial_fit_and_graph",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# first load the data\n",
    "data = np.load(\"data/xy_data.npy\")\n",
    "\n",
    "@interact\n",
    "def make_polynomial_fit_and_graph(polynomial_order=(0, 9), training_set_index=(1, 11)):\n",
    "    \"\"\"Finds the best-fitting polynomials for k = {0, ... , 9}, \n",
    "    using one of eleven different training datasets.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # relabel the parameters\n",
    "    k = polynomial_order\n",
    "    i = training_set_index\n",
    "    \n",
    "    # pull out the x and y values\n",
    "    x = data[((i - 1) * 10):(i * 10), 0]\n",
    "    y = data[((i - 1) * 10):(i * 10), 1]\n",
    "    \n",
    "    # create the figure\n",
    "    fig, axis = plt.subplots()\n",
    "\n",
    "    # create a range of values for x between 0 and 1\n",
    "    plotx = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "    # find the coefficients p\n",
    "    p = np.polyfit(x, y, k)\n",
    "\n",
    "    # find the values of the polynomial parameterized by p and \n",
    "    # evaluated for the points plotx\n",
    "    ploty = np.polyval(p, plotx)\n",
    "\n",
    "    # plot the fitted function\n",
    "    axis.plot(plotx, ploty, 'b-', label=\"${}$\".format(format_equation(p)))\n",
    "\n",
    "    # plot the original data points\n",
    "    axis.plot(x, y, 'ko')\n",
    "    \n",
    "    # set the axis limits\n",
    "    axis.set_xlim(0, 1)\n",
    "    axis.set_ylim(0, 0.35)\n",
    "\n",
    "    # put a title on each plot\n",
    "    axis.set_title('Dataset #{} fitted with k = {}'.format(i, k))\n",
    "    \n",
    "    # create a legend\n",
    "    axis.legend(loc='upper left', frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Examine the figure that is produced. Try changing the widget sliders to change the dataset that we are fitting the polynomial to, and the degree of that polynomial. Which degree polynomial both results in similar fits (i.e. similar coefficients) across all datasets _and_ does a good job at capturing the data?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8744ea4fdcc8267df64fcb6fe0bc4c7e",
     "grade": true,
     "grade_id": "part_a",
     "points": 0.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">How can the above result be understood in terms of the bias and variance tradeoff we discussed in class?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b76a983a3ecfd4bdfeb301ab0f0e781d",
     "grade": true,
     "grade_id": "part_a2",
     "locked": false,
     "points": 0.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part B (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "To get a more quantitative sense of how well each polynomial order fits the data, we'll now compute the actual mean squared error (MSE) of the polynomial fits in relationship to both a *training* dataset and a *testing* dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Complete the function `mse` to compute the MSE for a polynomial with order $k$ that has been fitted to the training data. The completed `mse` function should return a tuple containing the MSE values for the training data and the test data.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d03138435844e846f5c3b254b35ca85f",
     "grade": false,
     "grade_id": "mse",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mse(k, train, test):\n",
    "    \"\"\"Fits a polynomial with order `k` to a training dataset, and \n",
    "    then returns the mean squared error (MSE) between the y-values\n",
    "    of the training data and the fitted polynomial, and the MSE\n",
    "    between the y-values of the test data and the fitted polynomial.\n",
    "    \n",
    "    Your answer can be done in 6 lines of code, including the return\n",
    "    statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    k : integer\n",
    "        The polynomial order\n",
    "    train : numpy array with shape (n, 2)\n",
    "        The training data, where the first column corresponds to the\n",
    "        x-values, and the second column corresponds to the y-values\n",
    "    test : numpy array with shape (m, 2)\n",
    "        The testing data, where the first column corresponds to the\n",
    "        x-values, and the second column corresponds to the y-values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a 2-tuple consisting of the training set MSE and testing set MSE\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "For example, we can compute the MSE for $k=2$ by using the first ten datapoints as training data, and the other datapoints as testing data, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = np.load(\"data/xy_data.npy\")\n",
    "\n",
    "# compute the MSE\n",
    "train_mse, test_mse = mse(2, data[:10], data[10:])\n",
    "print(\"The training error is: {}\".format(train_mse))\n",
    "print(\"The testing error is:  {}\".format(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c669b3ae0b7f0d7b6534d5add4706ea7",
     "grade": true,
     "grade_id": "test_mse",
     "points": 1
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Test that the `mse` function is correct.\"\"\"\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "data = np.load(\"data/xy_data.npy\")\n",
    "\n",
    "# use first ten, and the remaining\n",
    "assert_allclose(mse(2, data[:10], data[10:]), (0.000229744955167, 0.000374298371336))\n",
    "assert_allclose(mse(3, data[:10], data[10:]), (0.000169612346303, 0.000463251756094))\n",
    "assert_allclose(mse(9, data[:10], data[10:]), (1.46448764925e-21, 0.337001581723), atol=1e-20)\n",
    "\n",
    "# use half-and-half\n",
    "assert_allclose(mse(2, data[:55], data[55:]), (0.00034502281024316553, 0.00037620706341530435))\n",
    "assert_allclose(mse(3, data[:55], data[55:]), (0.0003378190977339938, 0.00039980736728858482))\n",
    "assert_allclose(mse(9, data[:55], data[55:]), (0.00026755111091101571, 0.00061531514687572487))\n",
    "\n",
    "# use last twenty, and the remaining\n",
    "assert_allclose(mse(2, data[-20:], data[:-20]), (0.00030881029910697136, 0.00040876086505745344))\n",
    "assert_allclose(mse(3, data[-20:], data[:-20]), (0.00021713262385879197, 0.00055653317636801015))\n",
    "assert_allclose(mse(9, data[-20:], data[:-20]), (0.00012210662449207329, 0.00071987940235435685))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part C (1 point)\n",
    "\n",
    "Next, complete the function template `plot_mse` to plot MSE versus $k$ for both `traindata` and `testdata`. Be sure to include a proper legend, title, and axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "81d706e0d731700e60f45803cfc5df80",
     "grade": false,
     "grade_id": "plot_mse",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_mse(axis, max_order, train, test):\n",
    "    \"\"\"Plot the mean squared error (MSE) for the given training and testing\n",
    "    data as a function of polynomial order. \n",
    "    \n",
    "    * Your plot should show the MSE for 0 <= k < max_order\n",
    "    * There should be two lines: one black, for the training set error, and\n",
    "      one red, for the testing set error.\n",
    "    * Make sure to include labels for the x- and y- axes.\n",
    "    * Label the training error and testing error lines as \"Training set error\" \n",
    "      and \"Testing set error\", respectively. These labels will be used to\n",
    "      create a legend later on (and so you should NOT actually create the\n",
    "      legend yourself -- just label the lines).\n",
    "      \n",
    "    Your answer can be done in 10 lines of code, including the return statement.\n",
    "      \n",
    "    Parameters\n",
    "    ----------\n",
    "    axis : matplotlib axis object\n",
    "        The axis on which to plot the MSE\n",
    "    max_order : integer\n",
    "        The maximum polynomial order to compute a fit for\n",
    "    train : numpy array with shape (n, 2)\n",
    "        The training data, where the first column corresponds to the\n",
    "        x-values, and the second column corresponds to the y-values\n",
    "    test : numpy array with shape (m, 2)\n",
    "        The testing data, where the first column corresponds to the\n",
    "        x-values, and the second column corresponds to the y-values\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array with shape (max_order, 2)\n",
    "        The MSE for the training data (corresponding to the first column) and\n",
    "        for the testing data (corresponding to the second column). Each row\n",
    "        corresponds to a different polynomial order.\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "After implementing the `plot_mse` function, you should be able to see the error as a function of the polynomial order for both the training set and the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = np.load(\"data/xy_data.npy\")\n",
    "\n",
    "# plot it\n",
    "fig, axis = plt.subplots()\n",
    "plot_mse(axis, 15, data[:20], data[20:])\n",
    "axis.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d03c9e73819596e818ba71ef24e9d347",
     "grade": true,
     "grade_id": "test_plot_mse",
     "points": 1
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Is the plot_mse function correctly implemented?\"\"\"\n",
    "from nose.tools import assert_equal, assert_not_equal\n",
    "from numpy.testing import assert_allclose\n",
    "from plotchecker import get_data\n",
    "\n",
    "data = np.load(\"data/xy_data.npy\")\n",
    "\n",
    "# check that it uses the mse function\n",
    "old_mse = mse\n",
    "del mse\n",
    "try:\n",
    "    fig, axis = plt.subplots()\n",
    "    plot_mse(axis, 9, data[:10], data[10:])\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"plot_mse should call mse, but it does not\")\n",
    "finally:\n",
    "    plt.close('all')\n",
    "    mse = old_mse\n",
    "    del old_mse\n",
    "    \n",
    "fig, axis = plt.subplots()\n",
    "error = plot_mse(axis, 9, data[:10], data[10:])\n",
    "axis.legend(loc='upper left')\n",
    "\n",
    "# check the error\n",
    "assert_equal(error.shape, (9, 2))\n",
    "assert_allclose(error[0], mse(0, data[:10], data[10:]))\n",
    "assert_allclose(error[4], mse(4, data[:10], data[10:]))\n",
    "assert_allclose(error[8], mse(8, data[:10], data[10:]))\n",
    "\n",
    "# check the plotted data\n",
    "plotted_data = get_data(axis)\n",
    "assert_equal(plotted_data.shape, (18, 2))\n",
    "assert_allclose(plotted_data[:9, 0], np.arange(9))\n",
    "assert_allclose(plotted_data[9:, 0], np.arange(9))\n",
    "assert_allclose(plotted_data[:9, 1], error[:, 0])\n",
    "assert_allclose(plotted_data[9:, 1], error[:, 1])\n",
    "\n",
    "# check the line colors\n",
    "assert axis.lines[0].get_color() in ['k', 'black', (0, 0, 0), '#000000']\n",
    "assert axis.lines[1].get_color() in ['r', 'red', (1, 0, 0), '#FF0000']\n",
    "\n",
    "# check the legend\n",
    "legend_labels = [x.get_text() for x in axis.get_legend().get_texts()]\n",
    "assert_equal(legend_labels, [\"Training set error\", \"Testing set error\"])\n",
    "\n",
    "# check the axis labels\n",
    "assert_not_equal(axis.get_xlabel(), \"\")\n",
    "assert_not_equal(axis.get_ylabel(), \"\")\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part D (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Now, we will use another IPython widget to visualize how the error changes depending on the dataset that we are fitting to. The widget will call your `plot_mse` function with different subsets of the data, depending on the index that is set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f2aabe0affa0b962a31a80ef1883e568",
     "grade": false,
     "grade_id": "visualize_mse",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = np.load(\"data/xy_data.npy\")\n",
    "\n",
    "@interact\n",
    "def visualize_mse(training_set_index=(1, 11)):\n",
    "    # relabel the index for convenience\n",
    "    i = training_set_index\n",
    "    \n",
    "    # pull out the training and testing data\n",
    "    traindata = data[((i - 1) * 10):(i * 10)]\n",
    "    testdata = np.concatenate([data[:((i - 1) * 10)], data[(i * 10):]])\n",
    "\n",
    "    # plot the MSE\n",
    "    fig, axis = plt.subplots()\n",
    "    plot_mse(axis, 10, traindata, testdata)\n",
    "    axis.set_ylim(0, 0.01)\n",
    "    axis.set_title(\"MSE for dataset #{}\".format(i))\n",
    "    axis.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Try changing the widget slider to explore the error on different datasets. What happens to the MSE on the training sets as the degree of the polynomial (i.e., the size of our hypothesis space) increases? What about on the test sets?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "561bd622b8514f51ab0176f6e1db36b5",
     "grade": true,
     "grade_id": "part_d",
     "points": 0.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Should you always use a learning algorithm that gives the best results on the training set? Justify your answer.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0f85252250c580bf29fff0d3b7674a83",
     "grade": true,
     "grade_id": "part_d2",
     "locked": false,
     "points": 0.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part E (1 point)\n",
    "  \n",
    "The MSE on the test set is an approximation of the *prediction error* associated with a particular learning algorithm. In class we discussed how *expected prediction error* is composed of a bias and a variance term. Both the bias and the variance depend upon the true function, $f$, that we are estimating with our learning algorithm.\n",
    "\n",
    "* An algorithm with high *bias* will systematically produce predictions that differ from the true function. This can happen in situations where the true function is more complex than the most complex function available to the algorithm.\n",
    "* An algorithm with high *variance* will produce predictions that can vary wildly depending on the specifics of the dataset we are evaluating. This can happen in situations where the algorithm is able to return functions that are more complex than the true function.\n",
    "\n",
    "For a more detailed explanation of the bias-variance tradeoff, please take a look at the reading by Geman et al. (1992)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Explain how the results from the MSE on `testset` could be explained in terms of the bias and variance of the learning algorithms involved. That is, in which cases does the bias of the learning algorithm dominate the MSE? In which cases does the variance dominate?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b15b28b14cdcdf465beb81a96a0c77a6",
     "grade": true,
     "grade_id": "part_e",
     "points": 0.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-success\">Explain how bias and variance are related to the degree of the polynomial in our model.</div>\n",
    "<!--<div class=\"alert alert-success\">Explain *why* either the bias or variance matters more in the different cases disussed above.</div>-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8e347daa05ec97253664a2c7bbbb5da9",
     "grade": true,
     "grade_id": "part_e2",
     "locked": false,
     "points": 0.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your problem set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {
    "20fb91264d73476293d305a36c9d5057": {
     "views": [
      {
       "cell_index": 33
      }
     ]
    },
    "48b11bcc67b548028ca74ebd12e5a75b": {
     "views": [
      {
       "cell_index": 12
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
