{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "outputs": [],
   "source": [
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-info\">**Hint**: Much of the material covered in this problem is introduced in the AIMA3/AIMA2 Chapter 13 reading. If you are having trouble with the questions here, that might be a good place to look.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Introduction\n",
    "\n",
    "Suppose you pull a coin from your pocket and want to know whether it is fair or biased. Let $\\theta$ denote the probability that the coin produces heads (`H`) each time you flip it, and assume that successive flips are independent.  You have two hypotheses: \n",
    " - $h_0$: the coin is fair, with $\\theta = 0.5$\n",
    " - $h_1$: the coin is biased, with $\\theta = 0.95$.\n",
    " \n",
    "_A priori_, you think your coin is more likely to be fair, although you know that a biased coin is still a distinct possibility. To reflect this intuition, you choose priors $P(h_0) = 0.6$ and $P(h_1) = 0.4$.\n",
    "\n",
    "Recall from class that you can use Bayes' rule to calculate the probability of a particular hypothesis being true given some data. Bayes' rule states that\n",
    "\n",
    "  \\begin{equation}\n",
    "    P(h|d)=\\frac{P(d|h)P(h)}{\\sum_{h'}P(d|h')P(h')}\n",
    "  \\end{equation}\n",
    "  \n",
    "where the term $P(h|d)$ is the *posterior* probability of a particular hypothesis $h$ being true given some data $d$. $P(d|h)$ is the *likelihood* of seeing the data $d$ if the hypothesis $h$ was true. $P(h)$ is the *prior* probability of $h$ being true which measures the strength of your belief in $h$ _before_ your observed the data $d$.\n",
    "\n",
    "For more background on probability and Bayes rule, see Chapter 13 of the course's texbook 'Artificial Intelligence: A modern approach' and especially Section 5 of Chapter 13."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part A (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Imagine you flip your coin once and it comes up heads. Let $d$ denote this data (i.e., the outcome of the coin flip). What is the probability of your data under $h_0$ and $h_1$ (i.e., what is $P(d|h_0)$ and $P(d|h_1)$)? To begin, complete the function template `likelihood` to compute the likelihood of the data under a particular hypothesis about $\\theta$.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-warning\">**Hint**: If you're stuck, look into Bernoulli random variables.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "87c27b95c721b39ffe127ea6a8441dc6",
     "grade_id": "likelihood",
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def likelihood(data, theta):\n",
    "    \"\"\"\n",
    "    Returns the likelihood of obtaining a particular sequence of flips using a \n",
    "    coin of bias theta.\n",
    "    \n",
    "    Your solution can be done in one line of code, including the return\n",
    "    statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : a list of shape (n,)\n",
    "        A binary sequence of coin flips. Heads are 1's and Tails are 0's. \n",
    "        \n",
    "    theta : float\n",
    "        A value between 0 and 1 representing the hypothesized coin's bias. \n",
    "        The probability that a coin produces Heads each time it is flipped.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    likelihood : float\n",
    "        The probability of getting the observed sequence using the hypothesized \n",
    "        coin.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e603ebbab58641d58529a995d47dc5ea",
     "grade": true,
     "grade_id": "test_likelihood",
     "points": 1.5
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check likelihood computes the correct values\"\"\"\n",
    "from nose.tools import assert_equal\n",
    "# create fake data and hypotheses\n",
    "val = np.array([[0], [1, 1, 0], [0, 1, 1], [0, 0]])\n",
    "hyp = np.array([0.5, 0.0, 1.0, 0.75])\n",
    "\n",
    "# correct answers\n",
    "ans = np.array([[0.5, 1.0, 0.0, 0.25], \n",
    "                [0.125, 0.0, 0.0, 0.140625], \n",
    "                [0.125, 0.0, 0.0, 0.140625], \n",
    "                [0.25, 1.0, 0.0, 0.0625]])\n",
    "\n",
    "for idi, i in enumerate(val):\n",
    "    for idj, j in enumerate(hyp):\n",
    "        assert_equal(ans[idi, idj], likelihood(i,j), \"Incorrect likelihood computed on a test case\")\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Now, use your completed `likelihood` function to implement Bayes' rule to compute the posterior probabilities for a collection of hypotheses and their priors.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aaaae09f638cc278f8819e9a4350a82e",
     "grade": false,
     "grade_id": "posteriors",
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def posteriors(data, thetas, priors):\n",
    "    \"\"\"\n",
    "    Computes the posterior probabilities of a collection of hypotheses \n",
    "    given their prior probabilities and some data.\n",
    "    \n",
    "    Your solution can be done in two lines of code, including the\n",
    "    return statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : a list of shape (n,)\n",
    "        A binary sequence of the observed heads (represented as 1's) and \n",
    "        tails (represented as 0's) generated by flipping a coin n times.\n",
    "        \n",
    "    thetas : numpy array of shape (m,)\n",
    "        An array of values between 0 and 1 representing the hypothesized \n",
    "        probability that a coin produces Heads each time it is flipped.\n",
    "        \n",
    "    priors : numpy array of shape (m,)\n",
    "        An array of values between 0 and 1 representing the probabilities\n",
    "        that the corresponding hypothesis in theta is true BEFORE \n",
    "        observing the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    posteriors : numpy array of shape (m,)\n",
    "        An array of values between 0 and 1 representing the probabilities\n",
    "        of the items in thetas given their prior probabilities and the \n",
    "        observed data.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Now we are ready to find out how strongly we should belief that the coin is fair after we have seen it come up heads once.\n",
    "\n",
    "So let's use the `posteriors` function on the values of $\\theta$ and priors defined above (i.e., $\\theta=0.5$ for $h_0$, $\\theta=0.95$ for $h_1$, $P(h_0)=0.6$, and $P(h_1)=0.4$). As a sanity check, let's verify that the posterior distribution over the hypothesis space sums to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "data = np.ones(1)\n",
    "thetas = np.array([0.5, 0.95])\n",
    "priors = np.array([0.6, 0.4])\n",
    "print(\"Posteriors: \" + str(posteriors(data, thetas, priors)))\n",
    "print(\"Total sum:  \" + str(np.sum(posteriors(data, thetas, priors))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Interesting! So after observing the coin come up heads once we should think that it is slightly less likely to be fair than we originally thought and slightly more likely to be biased. This makes sense because the biased coin is more likely to come up heads than the fair coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7f5c5d21f3efa600943f3f4dd0737113",
     "grade": true,
     "grade_id": "test_posteriors",
     "points": 1.5
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that posteriors computes the correct values\"\"\"\n",
    "from numpy.testing import assert_array_almost_equal\n",
    "\n",
    "# create fake data, hypotheses, and priors\n",
    "vals = np.array([[0, 1, 1, 1, 0, 1], [0, 0,1]])\n",
    "hyps = np.array([[0.5, 0.95], [0.3, 0.2],[0.99,0.01],[0.5,0.6]])\n",
    "pri = np.array([[0.6, 0.4], [0.1, 0.9],[0,1],[1,0]])\n",
    "\n",
    "# correct answers\n",
    "ans = np.array([[0.92006421, 0.07993579], \n",
    "                [0.30102389, 0.69897611],\n",
    "                [0,1],\n",
    "                [1,0],\n",
    "                [0.98749177, 0.01250823],\n",
    "                [0.11316397, 0.88683603],\n",
    "                [0,1],\n",
    "                [1,0]])\n",
    "\n",
    "p = []\n",
    "for idi, i in enumerate(vals):\n",
    "    for idj, j in enumerate(hyps):\n",
    "        p.append(posteriors(i, j, pri[idj]))\n",
    "assert_array_almost_equal(np.asarray(p), ans, err_msg=\"Incorrect posterior\")\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part B (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Complete the function `plot_heads` to graph the change in the posterior probability of the hypothesis $h_1$ according to which $\\theta = \\text{thetas}[1]$ as the agent observes a sequence of $1,2,\\ldots,N$ heads. This means that you must compute the posterior probability $P(\\theta=\\text{thetas}[1]\\,|\\,d_n)$ where $d_n$ is a sequence of $n$ 1's for all $n \\in \\{1,2,\\cdots,N\\}$. Don't forget to label your axes!</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e379a0674047763f98d1d73f95192729",
     "grade_id": "plot_heads",
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_heads(axis, N, thetas, priors):\n",
    "    \"\"\"\n",
    "    Generate a plot showing the change in posterior probability of h_1 according to which theta=thetas[1]\n",
    "    as a function of sequence length.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    axis : matplotlib axis object\n",
    "    \n",
    "    N : int\n",
    "        The maximum length of a data sequence. This determines the upper\n",
    "        bound on the X axis of the plot\n",
    "        \n",
    "    thetas : numpy array of shape (m,)\n",
    "        An array of values between 0 and 1 representing the hypothesized \n",
    "        probability that a coin produces Heads each time it is flipped.\n",
    "        \n",
    "    priors : numpy array of shape (m,)\n",
    "        An array of values between 0 and 1 representing the probabilities\n",
    "        that the corresponding hypothesis in theta is true BEFORE \n",
    "        observing the data.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Run `plot_heads` with `N` = 10 using the `thetas` and `priors` supplied in Part A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "thetas = np.array([0.5, 0.95])\n",
    "priors = np.array([0.6, 0.4])\n",
    "fig, axis = plt.subplots()\n",
    "plot_heads(axis, N, thetas, priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "50684e5faac217cda8934ed5fabae154",
     "grade": true,
     "grade_id": "test_plot_heads",
     "points": 1
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check the implementation of plot_heads\"\"\"\n",
    "from plotchecker import get_data\n",
    "from nose.tools import assert_equal, assert_not_equal\n",
    "from numpy.testing import assert_array_almost_equal\n",
    "\n",
    "# create fake N, hypotheses, and priors\n",
    "N = 8\n",
    "hyps = np.array([[0.5, 0.95], [0.3, 0.2]])\n",
    "pri = np.array([[0.6, 0.4], [0.1, 0.9]])\n",
    "ans = np.array([[0.55882353, 0.70645793, 0.8205527, 0.89678023, 0.94288106, 0.9691014, 0.98349602, 0.99124525],\n",
    "                [0.85714286, 0.8, 0.72727273, 0.64, 0.54237288, 0.44137931, 0.34501348, 0.25989848]])\n",
    "\n",
    "for idj, j in enumerate(hyps):\n",
    "    # plot data\n",
    "    fig, axis = plt.subplots()\n",
    "    plot_heads(axis, N, j, pri[idj])\n",
    "    \n",
    "    # check plot data\n",
    "    plot_data = get_data(axis)\n",
    "    assert_array_almost_equal(plot_data, np.vstack([np.arange(1, N+1), ans[idj]]).T)\n",
    "\n",
    "    # check axis labels and title\n",
    "    assert_not_equal(axis.get_xlabel(), '', \"No x axis label given\")\n",
    "    assert_not_equal(axis.get_ylabel(), '', \"No y axis label given\")\n",
    "    assert_not_equal(axis.get_title(), '', \"No title given\")\n",
    "\n",
    "    # close the plot\n",
    "    plt.close(fig)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part C (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">Using the plot in Part B, describe what happens to the posterior probability of $h_1$ as the length of the sequence increases. Why should this be the case?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "512161138099d31c2e89c1fcdc37d4b0",
     "grade": true,
     "grade_id": "bayes-partc",
     "points": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your problem set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
