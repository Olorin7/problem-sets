{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". As a reminder, there is **NO COLLABORATION** whatsoever on the final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from EM import p_multivariate_gaussian, plot_true_clusters, EM_algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "This problem explores the properties of the Expectation Maximization (EM) algorithm, which is often used for unsupervised learning. The EM algorithm can be analyzed in contrast to the $k$-means clustering algorithm, which you explored on the last problem set. In this problem, we'll be exploring the same dataset consisting of cats, dogs, and mops. An example observation from each type of object is presented below:\n",
    "![](images/test.png)\n",
    "We assume each point can be represented as a pair of ($x,y$) coordinates, i.e., each object is represented in two-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part A (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "What are the **three** main differences between the $k$-means algorithm and the general clustering version of the EM algorithm? Please state the differences using a numbered or bulleted list.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "68631e8906e7f87387993bb9b3b4793e",
     "grade": true,
     "grade_id": "k-means-em-differences",
     "points": 1.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part B (2 points)\n",
    "\n",
    "In this problem, you will implement the EM algorithm for a mixture of Gaussians. Your algorithm will take in a set of points in two-dimensional space, and find clusters within the data by assuming that each point was generated from a probability distribution consisting of a mixture of Gaussians. The EM algorithm accomplishes this by iterating over two steps:\n",
    "\n",
    "1. **E step**: assign each data point to a cluster based on the probability of belonging to that cluster.\n",
    "2. **M step**: find the maximum-likelihood (ML) parameter estimates of the clusters based on which points are assigned to them.\n",
    "\n",
    "First, we will implement the \"E step\" of the EM algorithm. Remember that the expectation step involves computing the probability of cluster assignment $c_i$ for the $i^\\mathrm{th}$ point given the data $x_i$ and cluster parameters $\\theta$ (in the case of Gaussians, the cluster parameters are the mean and covariance of the distribution):\n",
    "\n",
    "$$\n",
    "P(c_i=j\\ |\\ x_i, \\theta)=\\frac{P(x_i\\ |\\ c_i=j, \\theta)P(c_i=j\\ |\\ \\theta)}{\\sum_c P(x_i\\ |\\ c, \\theta)P(c\\ |\\ \\theta)}\n",
    "$$\n",
    "\n",
    "Note that in this problem, we are going to assume all the clusters are *a priori* equally likely â€” that is, that $P(c=j\\ |\\ \\theta)$ is the same for all clusters $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Complete the function below to compute the expectation step of the EM algorithm, which is the probability of each cluster given each data point. You should use the provided function `p_multivariate_gaussian` to help compute the probabilities. You can look up documentation on `p_multivariate_gaussian` by running the cell below:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "p_multivariate_gaussian?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "522356eeaaf3a4783b5865cf6f617365",
     "grade": false,
     "grade_id": "E_step",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def E_step(X, cluster_means, cluster_covariances):\n",
    "    \"\"\"Computes the probability of cluster assignments for each\n",
    "    data point in X, given the cluster parameters (Gaussian mean\n",
    "    and covariance).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array with shape (n, 2)\n",
    "        The x- and y- coordinates of the data points\n",
    "    cluster_means : numpy array with shape (k, 2)\n",
    "        The mean parameter for each cluster, such that cluster_means[j]\n",
    "        is the mean for the cluster j.\n",
    "    cluster_covariances : numpy array with shape (k, 2, 2)\n",
    "        The covariance parameter for each cluster, such that\n",
    "        cluster_covariances[j] is the covariance for cluster j.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    p : numpy array with shape (n, k)\n",
    "        The probability of cluster assignments for each data point, such\n",
    "        that p[i, j] is the probability that point i is assigned to\n",
    "        cluster j.\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "75d30f0e856e0221c063ed91264bc49f",
     "grade": true,
     "grade_id": "test_E_step",
     "points": 2
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that the expectation step is correct\"\"\"\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "# try two different data sets\n",
    "EM_test_data = np.load(\"data/EM_test_data.npz\")\n",
    "\n",
    "# this one has 5 data points and 2 clusters\n",
    "p1 = E_step(EM_test_data['X1'], EM_test_data['m1'], EM_test_data['c1'])\n",
    "assert_allclose(p1.sum(axis=1), np.ones(5), err_msg=\"Probabilities do not sum to one\")\n",
    "assert_allclose(EM_test_data['p1'], p1)\n",
    "\n",
    "# this one has 10 data points and 3 clusters\n",
    "p2 = E_step(EM_test_data['X2'], EM_test_data['m2'], EM_test_data['c2'])\n",
    "assert_allclose(p2.sum(axis=1), np.ones(10), err_msg=\"Probabilities do not sum to one\")\n",
    "assert_allclose(EM_test_data['p2'], p2)\n",
    "\n",
    "# this one has 30 data points and 3 clusters\n",
    "p3 = E_step(EM_test_data['X3'], EM_test_data['m3'], EM_test_data['c3'])\n",
    "assert_allclose(p3.sum(axis=1), np.ones(30), err_msg=\"Probabilities do not sum to one\")\n",
    "assert_allclose(EM_test_data['p3'], p3)\n",
    "\n",
    "# check that p_multivariate_gaussian is used\n",
    "old_p_multivariate_gaussian = p_multivariate_gaussian\n",
    "del p_multivariate_gaussian\n",
    "try:\n",
    "    E_step(EM_test_data['X2'], EM_test_data['m2'], EM_test_data['c2'])\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"E_step does not call p_multivariate_gaussian\")\n",
    "finally:\n",
    "    p_multivariate_gaussian = old_p_multivariate_gaussian\n",
    "    del old_p_multivariate_gaussian\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part C (2 points)\n",
    "\n",
    "Now that we have completed the expectation step, the next thing we need to do is to implement the maximization step. The maximization step involves updating both the mean and covariance parameters of the clusters. In this problem, you will write code to update the mean parameters; we will provide you with code that updates the covariances.\n",
    "\n",
    "Recall that the updated mean $\\mu_j$ for cluster $j$ can be computed according to:\n",
    "\n",
    "$$\n",
    "\\mu_j = \\frac{\\sum_{i=1}^n x_i\\cdot{} P(c_i=j\\ |\\ x_i, \\theta)}{\\sum_{i=1}^n P(c_i=j\\ |\\ x_i, \\theta)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Complete the function `update_means` to compute the updated means for each cluster given the data points and the cluster assignment probabilities.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "34faf81dcb406a13caadb1cc4d0d4a9f",
     "grade": false,
     "grade_id": "update_means",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def update_means(X, p):\n",
    "    \"\"\"Updates the estimate of the means of the clusters given\n",
    "    the data and the probability of cluster assignments.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array with shape (n, 2)\n",
    "        The x- and y- coordinates of the data points\n",
    "    p : numpy array with shape (n, k)\n",
    "        The probability of cluster assignments for each data point, such\n",
    "        that p[i, j] is the probability that point i is assigned to\n",
    "        cluster j.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    cluster_means : numpy array with shape (k, 2)\n",
    "        The mean parameter for each cluster, such that cluster_means[j]\n",
    "        is the mean for the cluster j.\n",
    "    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6970eb11cad094e6951cd6706893b988",
     "grade": true,
     "grade_id": "test_update_means",
     "points": 2
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check if update_means is correct.\"\"\"\n",
    "\n",
    "# try two different data sets\n",
    "EM_test_data = np.load(\"data/EM_test_data.npz\")\n",
    "\n",
    "# this one has 5 data points and 2 clusters\n",
    "m1_updated = update_means(EM_test_data['X1'], EM_test_data['p1'])\n",
    "assert_allclose(EM_test_data['m1_updated'], m1_updated)\n",
    "\n",
    "# this one has 10 data points and 3 clusters\n",
    "m2_updated = update_means(EM_test_data['X2'], EM_test_data['p2'])\n",
    "assert_allclose(EM_test_data['m2_updated'], m2_updated)\n",
    "\n",
    "# this one has 30 data points and 3 clusters\n",
    "m3_updated = update_means(EM_test_data['X3'], EM_test_data['p3'])\n",
    "assert_allclose(EM_test_data['m3_updated'], m3_updated)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part D (1 point)\n",
    "\n",
    "Now that we have a function for updating the cluster means, we can combine it with a function for updating the covariances to form the full maximization step. Here, we provide for you the code to update the covariances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "df9e0a5ba1d7ba93a8b53903d89e47e5",
     "grade": false,
     "grade_id": "update_covariances",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def update_covariances(X, p, cluster_means):\n",
    "    \"\"\"Updates the estimate of the covariances of the clusters given\n",
    "    the data, the probability of cluster assignments, and the updated\n",
    "    cluster means.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array with shape (n, 2)\n",
    "        The x- and y- coordinates of the data points\n",
    "    p : numpy array with shape (n, k)\n",
    "        The probability of cluster assignments for each data point, such\n",
    "        that p[i, j] is the probability that point i is assigned to\n",
    "        cluster j.\n",
    "    cluster_means : numpy array with shape (k, 2)\n",
    "        The mean parameter for each cluster, such that cluster_means[j]\n",
    "        is the mean for the cluster j.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    cluster_covariances : numpy array with shape (k, 2, 2)\n",
    "        The covariance parameter for each cluster, such that\n",
    "        cluster_covariances[j] is the covariance for cluster j.\n",
    "    \n",
    "    \"\"\"\n",
    "    regparam = 0.001\n",
    "    cluster_covariances = np.empty((p.shape[1], 2, 2))\n",
    "    for j in range(p.shape[1]):\n",
    "        diffs = (X - cluster_means[j]) * np.sqrt(p[:, j])[:, None]\n",
    "        cc = np.dot(diffs.T, diffs) / p[:, j].sum()\n",
    "        cluster_covariances[j] = cc * (1 - regparam) + np.eye(2) * regparam\n",
    "    return cluster_covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Complete the `M_step` function to use your `update_means` and `update_covariances` functions to perform the full maximization step. You should take a look at the documentation for `update_covariances` to figure out how to call it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "795a27331bf50782470fb549a7b7018b",
     "grade": false,
     "grade_id": "M_step",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def M_step(X, p):\n",
    "    \"\"\"Perform the maximization step of the EM algorithm given the\n",
    "    data and the probability of the cluster assignments.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array with shape (n, 2)\n",
    "        The x- and y- coordinates of the data points\n",
    "    p : numpy array with shape (n, k)\n",
    "        The probability of cluster assignments for each data point, such\n",
    "        that p[i, j] is the probability that point i is assigned to\n",
    "        cluster j.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    a tuple consisting of:\n",
    "        cluster_means : numpy array with shape (k, 2)\n",
    "            The mean parameter for each cluster, such that cluster_means[j]\n",
    "            is the mean for the cluster j.\n",
    "        cluster_covariances : numpy array with shape (k, 2, 2)\n",
    "            The covariance parameter for each cluster, such that\n",
    "            cluster_covariances[j] is the covariance for cluster j.\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "84686b996ae6a43e3986253978e7ee61",
     "grade": true,
     "grade_id": "test_M_step",
     "points": 1
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check if M_step is correct.\"\"\"\n",
    "\n",
    "# try two different data sets\n",
    "EM_test_data = np.load(\"data/EM_test_data.npz\")\n",
    "\n",
    "# this one has 5 data points and 2 clusters\n",
    "m1_updated, c1_updated = M_step(EM_test_data['X1'], EM_test_data['p1'])\n",
    "assert_allclose(EM_test_data['m1_updated'], m1_updated)\n",
    "assert_allclose(EM_test_data['c1_updated'], c1_updated)\n",
    "\n",
    "# this one has 10 data points and 3 clusters\n",
    "m2_updated, c2_updated = M_step(EM_test_data['X2'], EM_test_data['p2'])\n",
    "assert_allclose(EM_test_data['m2_updated'], m2_updated)\n",
    "assert_allclose(EM_test_data['c2_updated'], c2_updated)\n",
    "\n",
    "# this one has 30 data points and 3 clusters\n",
    "m3_updated, c3_updated = M_step(EM_test_data['X3'], EM_test_data['p3'])\n",
    "assert_allclose(EM_test_data['m3_updated'], m3_updated)\n",
    "assert_allclose(EM_test_data['c3_updated'], c3_updated)\n",
    "\n",
    "# check that update_means is used\n",
    "old_update_means = update_means\n",
    "del update_means\n",
    "try:\n",
    "    M_step(EM_test_data['X2'], EM_test_data['p2'])\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"M_step does not call update_means\")\n",
    "finally:\n",
    "    update_means = old_update_means\n",
    "    del old_update_means\n",
    "\n",
    "# check that update_covariances is used\n",
    "old_update_covariances = update_covariances\n",
    "del update_covariances\n",
    "try:\n",
    "    M_step(EM_test_data['X2'], EM_test_data['p2'])\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"M_step does not call update_covariances\")\n",
    "finally:\n",
    "    update_covariances = old_update_covariances\n",
    "    del old_update_covariances\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part E (2 points)\n",
    "\n",
    "Now, let's try running the EM algorithm on some actual data. As mentioned above, we'll be using the same dataset of cats, dogs, and mops from the previous problem set. The true cluster assignments for each of the points is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "88c9127f2987eda0c019ec157f623750",
     "grade": false,
     "grade_id": "plot_true_clusters",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.load(\"data/X.npy\")\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "plot_true_clusters(axis, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Now, let's run the EM algorithm on the data. Execute the cell below to watch the EM algorithm converge to a solution. Each point is colored with RGB values proportional to the probabilities of the cluster assignments (so if the cluster probabilities of a point are $[0.5, 0.5, 0]$, then the color of that point will be 50% red, 50% green, and 0% blue). The black ellipses show contours of the Gaussians corresponding to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "208a68761b3794dd85ac0c82baa56802",
     "grade": false,
     "grade_id": "centers1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "centers1 = np.array([\n",
    "    [ 3.63398062,  2.9905047 ],\n",
    "    [ 2.6300394 ,  4.0755554 ],\n",
    "    [ 2.90636624,  1.67106719]])\n",
    "\n",
    "EM_algorithm(X, E_step, M_step, centers1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Compare the plot on the left (depicting the clusters generated by the EM algorithm) with the plot on the right (depicting the true cluster assignments). How well does the EM algorithm do at clustering the points? Does it miscategorize any of the points?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "26d7633348d0e03ee22b360f39539c24",
     "grade": true,
     "grade_id": "part_e",
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part F (1.5 points)\n",
    "\n",
    "Let's see what happens if we initialize the EM algorithm with different cluster centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fe4af85e94915bad99a73d951f581392",
     "grade": false,
     "grade_id": "centers2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "centers2 = np.array([\n",
    "    [ 3.57939394,  2.98596398],\n",
    "    [ 3.54071059,  2.78969028],\n",
    "    [ 3.67321618,  2.9501688 ]])\n",
    "\n",
    "EM_algorithm(X, E_step, M_step, centers2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "You should be able to see that the EM algorithm didn't find quite the same clusters as the first time we ran it. Describe the way in which the clusters are different, and explain *why* we get different clusters when we start the algorithm with different initial parameters.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "834b30c76b9e91e2c44fa83fbb3001f7",
     "grade": true,
     "grade_id": "part_f",
     "points": 1.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part G (1.5 points)\n",
    "\n",
    "Let's run the EM algorithm one last time, again initializing the cluster means differently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e1504536e88f52f33dba5ec14749ddb8",
     "grade": false,
     "grade_id": "centers3",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "centers3 = np.array([\n",
    "    [ 3.12180098,  3.85053529],\n",
    "    [ 2.90932354,  4.26426491],\n",
    "    [ 2.6300394 ,  4.0755554 ]])\n",
    "\n",
    "EM_algorithm(X, E_step, M_step, centers3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Notice that each of the plots generated in Parts E, F, and G includes a *log-likelihood score* (abbreviated as LLH in the title of the plot). This is the logarithm of the likelihood of the data given the clusters. Based on these scores, which plot shows the best fit to the data? Do you think this plot is also the best match to the true cluster assignments? Explain why you think this.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ff853336abc25c1acdfcb49e87ae8a47",
     "grade": true,
     "grade_id": "part_g",
     "points": 1.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part H (2.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "We can use randomly generated cluster centers (rather than specifying them ourselves) by just leaving out the parameter for the initial cluster means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "EM_algorithm(X, E_step, M_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Run the EM algorithm with randomly generated cluster means several more times. Describe at least two mistakes that the algorithm frequently makes. How do the log likelihoods compare when the algorithm makes these errors, compared to when it doesn't?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da4f5edd86088f4b7633a7fca20c04af",
     "grade": true,
     "grade_id": "part_h1",
     "points": 2.5,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your exam.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
