{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". As a reminder, there is **NO COLLABORATION** whatsoever on the final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "In the gameshow *Deal or No Deal*, the contestant is presented with 26 closed briefcases numbered from 1 to 26, each containing a piece of paper with a different amount of money written on it. The amounts range from 0.01 to 1,000,000 USD and are posted on a board that everyone can see:\n",
    "\n",
    "<img src=\"images/deal-or-no-deal-board.gif\" alt=\"Deal or no deal board\" width=\"200px\"/>\n",
    "\n",
    "\n",
    "At the begnning of the show, the contestant selects a briefcase, but does not get to open it. Unless something happens, the amount written in that suitcase is how much the contestant will win at the end of the game. But what is the chosen suitcase worth? This is the essential question that drives the game's dynamic.\n",
    "\n",
    "On each round, the participant selects a briefcase to eliminate from those that remain. The selected briefcase is opened, revealing the dollar amount inside. The contestant thus learns that the originally-chosen suitcase does not contain that amount. It's struck off the board. \n",
    "\n",
    "Then the participant is confronted with a decision: continue playing by eliminating another suitcase and getting an even better estimate of the value of the briefcase in hand, or accept a deal offered by The Banker: take a fixed amount of money and end the game immediately. The amount of money offered by The Banker depends on the suitcases that remain.\n",
    "\n",
    "Should the contestant take the risk and continue playing, possibly beating The Banker's offer? Or should the contestant accept the deal and walk away, money in hand? This is the game's essential tension, always present. It's what makes the show exciting. Deal, or no deal? \n",
    "\n",
    "If, by the end of the game, the contestant has not taken any of The Banker's offers, then the contestant walks away with the amount of money written in the suitcase that was chosen at the start of the show.\n",
    "\n",
    "If you are confused about how the game works, consider watching a bit of the show on YouTube. Here's a particularly exciting clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "YouTubeVideo(\"hmZFHjQfx-o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part A (1 point)\n",
    "\n",
    "Decision theory recommends that a contestant should accept the deal if the utility of The Banker's offer exceeds the expected utility of continuing to play. What *is* expected utility, you ask? First, consider the amount of money that is offered to the contestant. It's a number in units of dollars. But most of us don't experience life in units of dollars, and that's where utility comes into play. The utility function transforms dollars into *utility*, the satisfaction that a decision-maker will experience in receiving that amount of money. Using the utility function, it is straightforward to transform The Banker's offer into a utility. But what about the utility of continuing to play? We don't know it for sure, so instead we must compute the expected utility — the probability-weighted average utility of all possible futures.\n",
    "\n",
    "We can decide whether to accept or reject a deal by comparing the offer's utility to the *expected utility* of continuing to play. Note that if the contestant continues playing, there are as many possible outcomes as there are dollar values remaining on the board, and these outcomes are all equally likely. Thus the expected utility of the action \"continue-to-play\" $A$ is given by the probability-weighted average utility over all possible outcomes, $o\\in A$:\n",
    "\n",
    "$$E[U(A)] = \\sum_{o\\in A} p(o)U(o)$$\n",
    "\n",
    "For example, if three briefcases remain (\\$10, \\$300, and \\$5,000), then the expected utility of rejecting a deal and keeping the current case is:\n",
    "\n",
    "$$E[U] = p(\\$10)U(\\$10) + p(\\$300)U(\\$300) + p(\\$5000)U(\\$5000),$$\n",
    "\n",
    "where $p(x)$ is the probability of receiving $x$ dollars and $U(x)$ is the utility of receiving $x$ dollars.\n",
    "\n",
    "The expected utility thus depends both on the probability of the possible outcomes and on the utility function $U$. For this problem, we will assume the cases are equally likely to be chosen. We will explore various choices of the utility function, $U$.\n",
    "\n",
    "One of the simplest utility functions is a linear utility function, which equates utility with dollars.  \n",
    "\n",
    "- `linear` — equates utility with dollar amount,\n",
    "  i.e. $U(x)=x$\n",
    "  \n",
    "However, a classic result in the study of economics and decision-making is that people are risk-averse for gains: they will take a fixed outcome over a gamble with the same expected utility when money and utility are equated. Given a choice between \\$0.50 and a gamble with a 50% chance of getting a dollar and a 50% chance of gettling nothing, they'll choose the sure thing over the gamble. This can be explained by a concave utility function, such as the logarithm:\n",
    "\n",
    "- `log` — natural logarithm of the dollar\n",
    "  amount, i.e. $U(x)=\\log{x}$\n",
    "  \n",
    "Other concave utility functions have been proposed, too:\n",
    "  \n",
    "- `sqrt` — square root of the dollar amount,\n",
    "  i.e. $U(x)=\\sqrt{x}$\n",
    "- `negexp` — negative exponential of the dollar amount,\n",
    "  i.e. $U(x)=1-e^{-x/200000}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">To compare these various utility functions, complete the function `utility`. This function takes a $N$-length vector of dollar amounts, `x`, and the name of a utility function, `utility_function`, and computes the utility of each value of `x` using the given utility function. The four utility functions you should implement are described above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3e68b288e55cbb3fbd12e6bba75019ab",
     "grade_id": "utility",
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def utility(x, utility_function):\n",
    "    \"\"\"Compute the utility.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array\n",
    "        A numpy array with shape (N,) containing dollar values.\n",
    "    utility_function : string\n",
    "        The name of the utility function (\"linear\", \"log\", \"sqrt\", or \"negexp\").\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        A numpy array with shape (N,) corresponding to the utility of\n",
    "        each value in x under the named utility function.\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Here's a cell to test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9fda8c85b7e83394e6359e8ffe1ca77a",
     "grade": true,
     "grade_id": "test_utility",
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that utility is implemented correctly.\"\"\"\n",
    "\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([ 0.60726381,  0.41245142,  0.90066819,  0.4128766 ,  0.47827406])\n",
    "arr3 = np.array([ 7.,  7.,  2.,  5.,  7.,  6.,  7.,  1.,  4.,  2.])\n",
    "\n",
    "# Test linear utility function\n",
    "assert_allclose(utility(arr1, 'linear'), arr1)\n",
    "assert_allclose(utility(arr2, 'linear'), arr2)\n",
    "assert_allclose(utility(arr3, 'linear'), arr3)\n",
    "    \n",
    "# Test log utility function\n",
    "expected_log_1 = np.array([ 0.        ,  0.69314718,  1.09861229,  1.38629436])\n",
    "expected_log_2 = np.array([-0.49879197, -0.88563685, -0.10461836, -0.88460652, -0.73757136])\n",
    "expected_log_3 = np.array([ \n",
    "    1.94591015,  1.94591015,  0.69314718,  1.60943791,  1.94591015,\n",
    "    1.79175947,  1.94591015,  0.        ,  1.38629436,  0.69314718])\n",
    "\n",
    "assert_allclose(utility(arr1, 'log'), expected_log_1)\n",
    "assert_allclose(utility(arr2, 'log'), expected_log_2)\n",
    "assert_allclose(utility(arr3, 'log'), expected_log_3)\n",
    "    \n",
    "# Test sqrt utility function\n",
    "expected_sqrt_1 = np.array([ 1.        ,  1.41421356,  1.73205081,  2.        ])\n",
    "expected_sqrt_2 = np.array([ 0.77927133,  0.64222381,  0.9490354 ,  0.64255474,  0.69157361])\n",
    "expected_sqrt_3 = np.array([ \n",
    "    2.64575131,  2.64575131,  1.41421356,  2.23606798,  2.64575131,\n",
    "    2.44948974,  2.64575131,  1.        ,  2.        ,  1.41421356])\n",
    "\n",
    "assert_allclose(utility(arr1, 'sqrt'), expected_sqrt_1)\n",
    "assert_allclose(utility(arr2, 'sqrt'), expected_sqrt_2)\n",
    "assert_allclose(utility(arr3, 'sqrt'), expected_sqrt_3)\n",
    "    \n",
    "# Test negexp utility function\n",
    "expected_negexp_1 = np.array([4.99998750e-06, 9.99995000e-06, 1.49998875e-05, 1.99998000e-05])\n",
    "expected_negexp_2 = np.array([3.03631444e-06, 2.06225497e-06, 4.50333081e-06, 2.06438087e-06, 2.39136744e-06])\n",
    "expected_negexp_3 = np.array([\n",
    "    3.49993875e-05, 3.49993875e-05, 9.99995000e-06, 2.49996875e-05, 3.49993875e-05,\n",
    "    2.99995500e-05, 3.49993875e-05, 4.99998750e-06, 1.99998000e-05, 9.99995000e-06])\n",
    "\n",
    "assert_allclose(utility(arr1, 'negexp'), expected_negexp_1)\n",
    "assert_allclose(utility(arr2, 'negexp'), expected_negexp_2)\n",
    "assert_allclose(utility(arr3, 'negexp'), expected_negexp_3)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part B (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "By graphing the utility functions, you can see how the relative utility of different amounts of money changes. To do this, we'll first create a function that lets you visualize the utility function for a range of values, in this case from \\$100 to \\$500,000 (including \\$500,000) in increments of \\$100. Complete the following function `plot_utility`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1cbf46c6214d1485815cf867c7fc6533",
     "grade_id": "plot_utility",
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_utility(axis, utility_function):\n",
    "    \"\"\"Plot a utility function over the range $100 to $500,000 \n",
    "    (including $500,000) in increments of $100. You should make use \n",
    "    of your completed `utility` function to compute the utilities. \n",
    "    In addition:\n",
    "    \n",
    "    * give the plot an appropriate title which includes the name of\n",
    "      the utility function\n",
    "    * make sure you include x and y labels\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    axis : matplotlib axis object\n",
    "        The axis on which to plot the utility function\n",
    "    utility_function : string\n",
    "        The name of the utility function\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Once your function is done, you can use it to plot any of the utility functions, for example the log utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots()\n",
    "plot_utility(axis, 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "83ddd4d7c423bc1a73c87c69a6f6021a",
     "grade": true,
     "grade_id": "test_plot_utility",
     "points": 2
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that plot_utility is correct\"\"\"\n",
    "from numpy.testing import assert_array_equal\n",
    "from nose.tools import assert_equal\n",
    "\n",
    "functions = ['linear', 'log', 'sqrt', 'negexp']\n",
    "fig, axes = plt.subplots(1, 4)\n",
    "for i in range(len(functions)):\n",
    "    axis = axes[i]\n",
    "    plot_utility(axis, functions[i])\n",
    "    \n",
    "    # check that only one thing is plotted\n",
    "    assert_equal(len(axis.lines), 1)\n",
    "    \n",
    "    # check the xdata\n",
    "    assert_array_equal(axis.lines[0].get_xdata(), np.arange(100, 500100, 100))\n",
    "    # check the ydata\n",
    "    assert_array_equal(axis.lines[0].get_ydata(), utility(np.arange(100, 500100, 100), functions[i]))\n",
    "    \n",
    "    # check the axis labels\n",
    "    assert axis.get_xlabel() != ''\n",
    "    assert axis.get_ylabel() != ''\n",
    "    \n",
    "    # check the title\n",
    "    assert functions[i] in axis.get_title(), \"the utility function name is not in the plot title\"\n",
    "plt.close()\n",
    "  \n",
    "# make sure it calls the utility function\n",
    "fig, axis = plt.subplots()\n",
    "old_utility = utility\n",
    "del utility\n",
    "try:\n",
    "    plot_utility(axis, 'log')\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"plot_utility does not call utility\")\n",
    "finally:\n",
    "    utility = old_utility\n",
    "    del old_utility\n",
    "    plt.close()\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part C (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Run the cell below to create plots for all four of the utility functions. Examine the slopes of these functions. How do the slopes vary? How do they relate to the amount of risk averseness in each utility function? Make sure you refer to *all* of the different functions in your answer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-warning\"> **NB**. Upon running the code below, you should see four separate plots, each with a different line plotted. If you do not, you probably have a bug in your `plot_utility` function from Part B!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e5d79c4e2bbcd6c9efab4d6d20483a54",
     "grade": false,
     "grade_id": "plot_utility_functions",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# create a 2x2 grid of subplots\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "# plot each of the utility functions\n",
    "functions = ['linear', 'log', 'sqrt', 'negexp']\n",
    "for i in range(len(functions)):\n",
    "    plot_utility(axes.flat[i], functions[i])\n",
    "\n",
    "# make the figure bigger\n",
    "fig.set_figwidth(8)\n",
    "fig.set_figheight(8)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b757b1cc8d0bae1218675acdb49f6840",
     "grade": true,
     "grade_id": "explain-utility-functions",
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part D (1 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Let's now use our utility functions to compute the expected utility of continuing to play given that a certain set of suitcases remain. Assuming all the cases are equally likely to be chosen, complete the function `expected_utility` so that it computes the equation from Part A with the given utility function. You should again make use of your completed `utility` function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "45f3eabc474e660ae9f218174fa9c616",
     "grade_id": "expected_utility",
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def expected_utility(remaining_suitcases, utility_function):\n",
    "    \"\"\"Compute the expected utility of continuing to play.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    remaining_suitcases : numpy array\n",
    "        A numpy array with shape (N,) containing dollar values of\n",
    "        the remaining cases.\n",
    "    utility_function : string\n",
    "        The name of the utility function (\"linear\", \"log\", \"sqrt\", \n",
    "        or \"negexp\").\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "       The expected utility of the remaining suitcases under the \n",
    "       passed `utility_function`\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Here's a cell to test your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8abdbcb85b5809f71c994063fe251bbc",
     "grade": true,
     "grade_id": "test_expected_utility",
     "points": 1
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that expected_utility is correct\"\"\"\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([ 0.60726381,  0.41245142,  0.90066819,  0.4128766 ,  0.47827406])\n",
    "arr3 = np.array([ 7.,  7.,  2.,  5.,  7.,  6.,  7.,  1.,  4.,  2.])\n",
    "\n",
    "# check some different inputs\n",
    "assert_allclose(expected_utility(arr1, 'linear'), 2.5)\n",
    "assert_allclose(expected_utility(arr2, 'linear'), 0.56230681599999999)\n",
    "assert_allclose(expected_utility(arr3, 'linear'), 4.7999999999999998)\n",
    "assert_allclose(expected_utility(arr1, 'log'), 0.79451345758698633)\n",
    "assert_allclose(expected_utility(arr2, 'log'), -0.62224501212915961)\n",
    "assert_allclose(expected_utility(arr3, 'log'), 1.395742670012319)\n",
    "assert_allclose(expected_utility(arr1, 'sqrt'), 1.5365660924854931)\n",
    "assert_allclose(expected_utility(arr2, 'sqrt'), 0.74093177939662735)\n",
    "assert_allclose(expected_utility(arr3, 'sqrt'), 2.109699008928752)\n",
    "assert_allclose(expected_utility(arr1, 'negexp'), 1.2499906250518222e-05)\n",
    "assert_allclose(expected_utility(arr2, 'negexp'), 2.8115297067365931e-06)\n",
    "assert_allclose(expected_utility(arr3, 'negexp'), 2.3999647503747389e-05)\n",
    "\n",
    "# make sure it calls utility\n",
    "old_utility = utility\n",
    "del utility\n",
    "try:\n",
    "    expected_utility(np.array([1, 2, 3]), 'linear')\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"expected_utility does not call utility\")\n",
    "finally:\n",
    "    utility = old_utility\n",
    "    del old_utility\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part E (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "The contestant accepts the bank's offer if the expected utility of the offer exceeds the expected utility of continuing to play. Using both your `utility` and `expected_utility` functions, create a `contestant` function that plays the game, deciding whether to accept the deal.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "90360fe0f03999e23a877195d560e791",
     "grade_id": "contestant",
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def contestant(offer, remaining_suitcases, utility_function):\n",
    "    \"\"\"Play Deal or No Deal, deciding whether to accept The Banker's offer.\n",
    "    The contestant accepts the bank's offer if the expected utility of the \n",
    "    offer exceeds the expected utility of continuing to play.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    offer : float\n",
    "        The dollar value of the offer.\n",
    "    remaining_suitcases : numpy array\n",
    "        A numpy array with shape (N,) containing dollar values of the remaining cases.\n",
    "    utility_function : string\n",
    "        The name of the utility function (\"linear\", \"log\", \"sqrt\", or \"negexp\").\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    boolean\n",
    "        True if the contestant accepts the deal, otherwise False.\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Here is a cell to test out your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "response = contestant(104, np.array([110, 100]), 'linear')\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "12361ee2a79dcf84ae81f20e248ca6e6",
     "grade": true,
     "grade_id": "test_contestant",
     "points": 1
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Is contestant implemented correctly?\"\"\"\n",
    "\n",
    "# Some offers should be accepted.\n",
    "assert contestant(106, np.array([110, 100]), 'linear')\n",
    "assert contestant(105, np.array([110, 100]), 'log')\n",
    "\n",
    "# Other offers should be rejected.\n",
    "assert not contestant(104, np.array([110, 100]), 'linear')\n",
    "assert not contestant(104, np.array([110, 100]), 'log')\n",
    "\n",
    "# check some other values, too\n",
    "arr1 = np.array([1, 2, 3, 4])\n",
    "arr2 = np.array([ 0.60726381,  0.41245142,  0.90066819,  0.4128766 ,  0.47827406])\n",
    "arr3 = np.array([ 7.,  7.,  2.,  5.,  7.,  6.,  7.,  1.,  4.,  2.])\n",
    "\n",
    "assert not contestant(2.5, arr1, 'linear')\n",
    "assert contestant(3.5, arr1, 'linear')\n",
    "assert not contestant(0.56, arr2, 'linear')\n",
    "assert contestant(0.57, arr2, 'linear')\n",
    "assert not contestant(4.7, arr3, 'linear')\n",
    "assert contestant(4.9, arr3, 'linear')\n",
    "\n",
    "assert not contestant(2.213363839400643, arr1, 'log')\n",
    "assert contestant(2.22, arr1, 'log')\n",
    "assert not contestant(0.53, arr2, 'log')\n",
    "assert contestant(0.54, arr2, 'log')\n",
    "assert not contestant(4.03, arr3, 'log')\n",
    "assert contestant(4.04, arr3, 'log')\n",
    "\n",
    "assert not contestant(2.3610353565761373, arr1, 'sqrt')\n",
    "assert contestant(2.37, arr1, 'sqrt')\n",
    "assert not contestant(0.54, arr2, 'sqrt')\n",
    "assert contestant(0.55, arr2, 'sqrt')\n",
    "assert not contestant(4.45, arr3, 'sqrt')\n",
    "assert contestant(4.46, arr3, 'sqrt')\n",
    "\n",
    "assert not contestant(2.4999968749994781, arr1, 'negexp')\n",
    "assert contestant(2.5, arr1, 'negexp')\n",
    "assert not contestant(0.56, arr2, 'negexp')\n",
    "assert contestant(0.57, arr2, 'negexp')\n",
    "assert not contestant(4.7, arr3, 'negexp')\n",
    "assert contestant(4.8, arr3, 'negexp')\n",
    "\n",
    "# make sure it calls utility\n",
    "old_utility = utility\n",
    "del utility\n",
    "try:\n",
    "    contestant(106, np.array([110, 100]), 'linear')\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"contestant does not call utility\")\n",
    "finally:\n",
    "    utility = old_utility\n",
    "    del old_utility\n",
    "\n",
    "# make sure it calls expected_utility\n",
    "old_expected_utility = expected_utility\n",
    "del expected_utility\n",
    "try:\n",
    "    contestant(106, np.array([110, 100]), 'linear')\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"contestant does not call expected_utility\")\n",
    "finally:\n",
    "    expected_utility = old_expected_utility\n",
    "    del old_expected_utility\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part F (2 points)\n",
    "\n",
    "Which utility function do contestants actually use when playing the game? Researchers have collected game-play data from the show and modeled the utility functions and choice models used by the contestants and The Banker. In this question, you will determine, based on actual game-play data, which utility function provides the closest fit to human behavior.\n",
    "\n",
    "The data come in the form of an array where rows are dollar values (those on the board) and columns are game rounds. The value is `True` if that dollar value remains in play on the board and `False` if it has been eliminated. Your goal is to evaluate each utility function by tallying up the number of rounds where the predicted response matches that of the contestant.\n",
    "\n",
    "Here's an example history of the board from one particular contestant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "contestant_001 = dict(np.load(\"data/deal_or_no_deal/contestant_001.npz\"))\n",
    "contestant_001[\"board_history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "And here are the dollar values of the board:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "contestant_001[\"values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "And here are the offers made by The Banker on each round:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "contestant_001[\"offers\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "These are the decisions the contestant made on each round. `False` indicates that they rejected the deal, while `True` indicates that they accepted the deal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "contestant_001[\"decisions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "To compare our different utility functions, we will measure how well they predict the contestants' decisions using a metric called an [F-score](http://en.wikipedia.org/wiki/F1_score). We have provided a function `F_score` for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "17d45f406c0b82f9b51e540259781e29",
     "grade": false,
     "grade_id": "F_score",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def F_score(model, human):\n",
    "    \"\"\"Compute the F-score between model predictions\n",
    "    and human data. A larger F-score means that the model\n",
    "    predicts human behavior better.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : boolean numpy array with shape (n,)\n",
    "        The model decisions\n",
    "    human : boolean numpy array with shape (n,)\n",
    "        The human's decisions\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float : the F-score for the model\n",
    "\n",
    "    \"\"\"\n",
    "    TT = (model & human).sum()\n",
    "    TF = (model & ~human).sum()\n",
    "    FT = (~model & human).sum()\n",
    "\n",
    "    if TT == 0 and TF == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TT / (TT + TF)\n",
    "\n",
    "    if TT == 0 and FT == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = TT / (TT + FT)\n",
    "\n",
    "    if precision == 0 and recall == 0:\n",
    "        return 0\n",
    "\n",
    "    return 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Using the `F_score` function, as well as your `contestant` function, complete the `best_fitting_utility_fuction` below to compute F-scores for each of the utility functions:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4601f45c48eb9f5e787e47ce72acde3c",
     "grade_id": "best_fitting_utility_function",
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def best_fitting_utility_function(contestant_data, utility_functions):\n",
    "    \"\"\"Which utility function best fits the data? Your function should use your\n",
    "    contestant function from above to determine the decisions that a contestant\n",
    "    would make for the given board and offers, for each utility function. For \n",
    "    each utility function, you should compute the F-score for the model compared\n",
    "    to the contestant's real decisions. (The model is your `contestant` function, \n",
    "    using the given utility function.)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    contestant_data : dict\n",
    "        A dictionary containing the data for a contestant in the gameshow, with\n",
    "        the following keys and values:\n",
    "            board_history : (m, n) Numpy array\n",
    "                Whether the dollar values remain in each of n rounds.\n",
    "            values : (m,) Numpy array\n",
    "                All the possible dollar values at the start of the game.\n",
    "            offers : (n,) Numpy array\n",
    "                The dollar value of The Banker's offer.\n",
    "            decisions : (n,) Numpy array\n",
    "                Whether the contestant accepted the offer.\n",
    "    utility_functions : list\n",
    "        A list of the utility functions you should compare.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy array\n",
    "        The F-score for each utility function. The ith element should correspond to\n",
    "        utility_functions[i].\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "data = dict(np.load(\"data/deal_or_no_deal/contestant_001.npz\"))\n",
    "best_fitting_utility_function(data, [\"log\", \"linear\", \"sqrt\", \"negexp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "# add your own test cases here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1deae3223bfcafcd568b8c9916e6249a",
     "grade": true,
     "grade_id": "test_best_fitting_utility_function",
     "points": 2
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that best_fitting_utility_function is correct\"\"\"\n",
    "from numpy.testing import assert_array_equal\n",
    "\n",
    "data_001 = dict(np.load(\"data/deal_or_no_deal/contestant_001.npz\"))\n",
    "\n",
    "# make sure it calls the contestant function\n",
    "old_contestant = contestant\n",
    "del contestant\n",
    "try:\n",
    "    best_fitting_utility_function(data_001, [\"log\", \"linear\", \"sqrt\", \"negexp\"])\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"best_fitting_utility_function does not call contestant\")\n",
    "finally:\n",
    "    contestant = old_contestant\n",
    "    del old_contestant\n",
    "    \n",
    "# make sure it calls the F_score function\n",
    "old_F_score = F_score\n",
    "del F_score\n",
    "try:\n",
    "    best_fitting_utility_function(data_001, [\"log\", \"linear\", \"sqrt\", \"negexp\"])\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"best_fitting_utility_function does not call F_score\")\n",
    "finally:\n",
    "    F_score = old_F_score\n",
    "    del old_F_score\n",
    "\n",
    "assert_allclose(\n",
    "    best_fitting_utility_function(data_001, [\"log\", \"linear\", \"sqrt\", \"negexp\"]), \n",
    "    np.array([ 0.2       ,  0.        ,  0.22222222,  0.28571429]))\n",
    "assert_allclose(\n",
    "    best_fitting_utility_function(data_001, [\"log\", \"sqrt\", \"linear\", \"negexp\"]),\n",
    "    np.array([ 0.2       ,  0.22222222,  0.        ,  0.28571429]))\n",
    "\n",
    "data_002 = dict(np.load(\"data/deal_or_no_deal/contestant_002.npz\"))\n",
    "assert_allclose(\n",
    "    best_fitting_utility_function(data_002, [\"log\", \"linear\", \"sqrt\", \"negexp\"]),\n",
    "    np.array([ 0.22222222,  0.        ,  1.        ,  0.5       ]))\n",
    "assert_allclose(\n",
    "    best_fitting_utility_function(data_002, [\"log\", \"sqrt\", \"linear\", \"negexp\"]), \n",
    "    np.array([ 0.22222222,  1.        ,  0.        ,  0.5       ]))\n",
    "\n",
    "data_003 = dict(np.load(\"data/deal_or_no_deal/contestant_003.npz\"))\n",
    "assert_allclose(\n",
    "    best_fitting_utility_function(data_003, [\"log\", \"linear\", \"sqrt\", \"negexp\"]), \n",
    "    np.array([ 0.25      ,  0.        ,  0.33333333,  0.4       ]))\n",
    "assert_allclose(\n",
    "    best_fitting_utility_function(data_003, [\"log\", \"sqrt\", \"linear\", \"negexp\"]), \n",
    "    np.array([ 0.25      ,  0.33333333,  0.        ,  0.4       ]))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---\n",
    "## Part G (1 point)\n",
    "\n",
    "Let's examine how well the utility functions fit the different contestants, on average. The following cell will print out the average F-score for each model across all the contestants. A larger F-score means that the model is a better match to the contestants' decisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8e345a6bb352efafc7744cfc66ade629",
     "grade": false,
     "grade_id": "compute_best_fitting_utility_functions",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "utility_functions = [\"linear\", \"log\", \"sqrt\", \"negexp\"]\n",
    "\n",
    "# compute the F-score of each utility function for each participant\n",
    "scores = np.empty((47, 4))\n",
    "for i in range(1, 48):\n",
    "    data = dict(np.load(\"data/deal_or_no_deal/contestant_{:03d}.npz\".format(i)))\n",
    "    scores[i - 1] = best_fitting_utility_function(data, utility_functions)\n",
    "\n",
    "# print out the mean F-score of each utility function\n",
    "for j in range(len(utility_functions)):\n",
    "    print(\"{}: {}\".format(utility_functions[j], scores[:, j].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "How well does each function explain the contestants' decisions? Which is the best-fitting function? Which is the worst? (Make sure you mention all the functions in your answer).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0f4bfed9c26db9685dd9bfa444858881",
     "grade": true,
     "grade_id": "match-behavior",
     "points": 0.25,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "What do these results suggest about human utility functions?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "943ae53910f7ae716daac1ecd2863786",
     "grade": true,
     "grade_id": "interpretation",
     "points": 0.75,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "source": [
    "Before turning this problem in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "release"
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your exam.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {}
   },
   "outputs": [],
   "source": [
    "print(\"No errors!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
